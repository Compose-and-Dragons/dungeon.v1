https://research.nvidia.com/labs/lpr/slm-agents/
# Les Petits Modèles de Langage sont l'Avenir de l'IA Agentique

_NVIDIA Research - Laboratoire de Recherche en Apprentissage et Perception_

## Résumé

Les grands modèles de langage (LLM) sont souvent loués pour leurs performances quasi-humaines sur un large éventail de tâches et valorisés pour leur capacité à tenir une conversation générale. L'essor des systèmes d'IA agentique introduit cependant une multitude d'applications dans lesquelles les modèles de langage exécutent un petit nombre de tâches spécialisées de manière répétitive et avec peu de variations.

Nous présentons ici la position selon laquelle les petits modèles de langage (SLM) sont suffisamment puissants, intrinsèquement plus adaptés et nécessairement plus économiques pour de nombreuses invocations dans les systèmes agentiques, et constituent par conséquent l'avenir de l'IA agentique. Notre argumentation se fonde sur le niveau actuel des capacités exhibées par les SLM, les architectures communes des systèmes agentiques, et l'économie du déploiement des modèles de langage. Nous soutenons en outre que dans les situations où les capacités conversationnelles généralistes sont essentielles, les systèmes agentiques hétérogènes (c'est-à-dire les agents invoquant plusieurs modèles différents) constituent le choix naturel. Nous discutons des barrières potentielles à l'adoption des SLM dans les systèmes agentiques et présentons un algorithme général de conversion d'agents LLM vers SLM.

Notre position, formulée comme une déclaration de valeur, souligne l'importance de l'impact opérationnel et économique qu'un passage même partiel des LLM vers les SLM aura sur l'industrie des agents IA. Nous visons à stimuler la discussion sur l'utilisation efficace des ressources IA et espérons faire progresser les efforts pour réduire les coûts de l'IA d'aujourd'hui. Appelant à la fois aux contributions et aux critiques de notre position, nous nous engageons à publier toute correspondance de ce type sur ce site web.

## Recommandations Pratiques

Bien que notre article présente une déclaration de valeur plaidant pour l'utilisation de petits modèles de langage (SLM) dans les systèmes d'IA agentique, nous fournissons également des recommandations pratiques pour les organisations et développeurs cherchant à implémenter cette approche.

## Discussion Ouverte

Nous accueillons favorablement la correspondance sur le contenu de cet article, y compris les critiques, suggestions et contributions qui peuvent aider à affiner notre position et faire progresser la discussion sur l'utilisation efficace des ressources IA.

Si vous avez des commentaires ou souhaitez contribuer à la discussion, n'hésitez pas à nous contacter par e-mail à [agents@nvidia.com](mailto:agents@nvidia.com).

Les correspondances, lorsque l'auteur correspondant a donné son autorisation, seront publiées sur ce site web pour favoriser un dialogue ouvert au sein de la communauté de recherche et au-delà.

## Citation

```bibtex
@misc{belcak2025small,
    title = {Small Language Models are the Future of Agentic AI},
    author = {Belcak, Peter and Heinrich, Greg and Diao, Shizhe and Fu, Yonggan and Dong, Xin and Muralidharan, Saurav and Lin, Yingyan Celine and Molchanov, Pavlo},
    year = {2025},
    eprint = {2506.02153},
    archivePrefix= {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2506.02153},
    doi = {10.48550/arXiv.2506.02153}
}
```

## Auteurs Principaux

- Peter Belcak
- Greg Heinrich
- Shizhe Diao
- Yonggan Fu
- Xin Dong
- Saurav Muralidharan
- Yingyan Celine Lin
- Pavlo Molchanov

---

_Source : [NVIDIA Research - Laboratoire de Recherche en Apprentissage et Perception](https://research.nvidia.com/labs/lpr/slm-agents/)_