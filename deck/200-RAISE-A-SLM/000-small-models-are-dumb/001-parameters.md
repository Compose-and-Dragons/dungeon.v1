---
marp: true
theme: default
paginate: true
---
<style>
.dodgerblue {
  color: dodgerblue;
}
.indianred {
  color: indianred;
}
.forestgreen {
  color: forestgreen;
}
</style>
## Parameters ğŸ“Š


- **Model Capacity**: More parameters = <span class="dodgerblue">**ability to capture more complexity in data**</span>, but also require <span class="indianred">**more computational resources**</span>
- **Size Impact**: Parameter count directly affects model file size, <span class="indianred">**memory usage**</span>, and <span class="indianred">**inference speed**</span>
- **Trade-offs**: Higher parameter counts <span class="dodgerblue">**improve capability**</span> but <span class="indianred">increase hardware requirements</span> and <span class="indianred">**processing time**</span>


<!--
Les paramÃ¨tres d'un modÃ¨le sont les valeurs numÃ©riques (poids et biais) que
   le modÃ¨le apprend pendant l'entraÃ®nement pour effectuer ses prÃ©dictions.

  Dans un rÃ©seau de neurones :
  - Poids : dÃ©terminent l'importance des connexions entre neurones
  - Biais : permettent d'ajuster les seuils d'activation

  Plus un modÃ¨le a de paramÃ¨tres, plus il peut capturer de complexitÃ© dans
  les donnÃ©es, mais plus il consomme de ressources (mÃ©moire, calcul).

  Exemples :
  - GPT-3 : 175 milliards de paramÃ¨tres
  - Llama 2 7B : 7 milliards de paramÃ¨tres
  - Un petit modÃ¨le : quelques millions

  Le nombre de paramÃ¨tres influence directement :
  - La capacitÃ© du modÃ¨le (ce qu'il peut apprendre)
  - Sa taille sur disque
  - Le temps d'infÃ©rence
  - Les ressources nÃ©cessaires pour l'utiliser
-->

[â† Previous](000-small-models-are-dumb.md) | [Next â†’](002-temperature.md)
