---
marp: true
theme: default
paginate: true
---

<style>
.dodgerblue {
  color: dodgerblue;
}
</style>
## Parameters ðŸ“Š

- **Weights and Biases**: Numerical values learned during training that determine how neurons connect and activate in the neural network
- **Model Capacity**: More parameters = ability to capture more complexity in data, but also require more computational resources
- **Size Impact**: Parameter count directly affects model file size, memory usage, and inference speed
- **Scale Examples**: GPT-3 has 175B parameters, Llama 2 7B has 7B, <span class="dodgerblue">**while small models have just millions**</span>
- **Trade-offs**: Higher parameter counts improve capability but increase hardware requirements and processing time


<!--
Les paramÃ¨tres d'un modÃ¨le sont les valeurs numÃ©riques (poids et biais) que
   le modÃ¨le apprend pendant l'entraÃ®nement pour effectuer ses prÃ©dictions.

  Dans un rÃ©seau de neurones :
  - Poids : dÃ©terminent l'importance des connexions entre neurones
  - Biais : permettent d'ajuster les seuils d'activation

  Plus un modÃ¨le a de paramÃ¨tres, plus il peut capturer de complexitÃ© dans
  les donnÃ©es, mais plus il consomme de ressources (mÃ©moire, calcul).

  Exemples :
  - GPT-3 : 175 milliards de paramÃ¨tres
  - Llama 2 7B : 7 milliards de paramÃ¨tres
  - Un petit modÃ¨le : quelques millions

  Le nombre de paramÃ¨tres influence directement :
  - La capacitÃ© du modÃ¨le (ce qu'il peut apprendre)
  - Sa taille sur disque
  - Le temps d'infÃ©rence
  - Les ressources nÃ©cessaires pour l'utiliser
-->